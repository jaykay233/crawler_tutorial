{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正则 bs4 xpath pyquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片爬取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requests\n",
    "urllib和requests的作用一样，但是当requests一问世就迅速取代了urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "headers={\n",
    "    'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.71 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## requests\n",
    "url='https://bkimg.cdn.bcebos.com/pic/ac6eddc451da81cb2f9a02a25d66d01609243164?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U5Mg==,g_7,xp_5,yp_5/format,f_auto'\n",
    "response=requests.get(url=url,headers=headers)\n",
    "image_data=response.content\n",
    "with open('./data/pic1.jpeg','wb') as fp:\n",
    "    fp.write(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## urlib\n",
    "urllib.request.urlretrieve(url,'./data/pic1_cp.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用urllib无法进行UA伪装，而requests可以"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬取校花网中的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elements中包含了完整页面的源码数据，包括动态加载的数据；而network只包含了某个请求的数据（不包含动态加载）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：爬虫时一定要进行页面布局分析，如果当前页面没有动态加载数据，则可以直接使用Elements进行解析，否则只能使用network进行解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##要加上re.S回车和换行\n",
    "import re\n",
    "import os\n",
    "dirName='./data/imagelib'\n",
    "if not os.path.exists(dirName):\n",
    "    os.mkdir(dirName)\n",
    "url='http://www.521609.com/qingchunmeinv'\n",
    "page_text=requests.get(url=url,headers=headers).text\n",
    "ex='<li>.*?<img src=\"(.*?)\" width=.*?</li>'\n",
    "image_src_list = re.findall(ex,page_text,re.S)\n",
    "for src in image_src_list:\n",
    "    src = 'http://www.521609.com' + src\n",
    "    image_path = dirName + '/' + src.split('/')[-1]\n",
    "    urllib.request.urlretrieve(src,image_path)\n",
    "    print(src+\"下载成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据解析是用来实现聚焦爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup(fp,'lxml')\n",
    "BeautifulSoup(page_text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_text='<html><body><title>数据解析</title></body></html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(page_text,'lxml')\n",
    "## soup.tagName只返回第一次出现的满足要求的\n",
    "## soup.find(tagName, attribute_name=''):属性定位\n",
    "## soup.findAll():跟find一样，但是返回所有的\n",
    "soup.body\n",
    "soup.find('body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select选择器\n",
    "## >表示一个层级\n",
    "## 空格表示多个层级\n",
    "soup.select('body > title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".text返回该标签下所有文本内容 .string返回该标签下直系文本内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag['attribute']取属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三国演义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.shicimingju.com/book/sanguoyanyi.html'\n",
    "page_text_response = requests.get(url=url,headers=headers)\n",
    "page_text_response.encoding='utf-8'\n",
    "page_text = page_text_response.text\n",
    "soup = BeautifulSoup(page_text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = soup.select('.book-mulu > ul > li > a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('./data/sanguoyanyi.txt','w',encoding='utf-8')\n",
    "for a in a_list:\n",
    "    title = a.string\n",
    "    detail_url = 'http://www.shicimingju.com'+a['href']\n",
    "    response = requests.get(url=detail_url,headers=headers)\n",
    "    response.encoding='utf-8'\n",
    "    page_text_detail = response.text\n",
    "    soup = BeautifulSoup(page_text_detail,'lxml')\n",
    "    div_tag = soup.find('div',class_='chapter_content')\n",
    "    content = div_tag.text\n",
    "    fp.write(title + ':' + content + '\\n')\n",
    "    print(title, '保存成功！')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etree.parse('filename'):将本地html加载到该队相中 etree.HTML(page_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标签定位：  \n",
    "最左侧/表示该xpath表达式一定从根标签开始定位标签，即一定从html开始；  \n",
    "非最左侧的/表示一个层级；最左侧的//表示可以从任意标签开始定位；  \n",
    "属性定位tagName[@attribute='value']，接着后面可以继续根/  \n",
    "索引定位：//p[2]，下标从1开始  \n",
    "模糊匹配：  \n",
    "  //div[contains(@class,\"ng\")]  \n",
    "  //div[starts-with(@class,\"ta\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取文本  \n",
    "/text()  直系文本内容  \n",
    "//text() 所有文本内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取属性  \n",
    "/@attrName  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "tree = etree.HTML(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element title at 0x111905d08>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.xpath('/html/body/title')\n",
    "tree.xpath('/html//title')\n",
    "tree.xpath('//title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在局部数据解析中，xpath要使用./操作，./表示的就是当前的局部数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "http://pic.netbian.com/uploads/allimg/180826/113958-1535254798fc1c.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210628/220732-1624889252aba1.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210419/203429-1618835669e1dd.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210810/231712-16286086323788.jpg\n",
      "http://pic.netbian.com/uploads/allimg/180315/110404-152108304476cb.jpg\n",
      "http://pic.netbian.com/uploads/allimg/170725/103840-15009503208823.jpg\n",
      "http://pic.netbian.com/uploads/allimg/170609/123945-14969831856c4d.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210826/000055-16299072552135.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210812/230911-162878095180f6.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210822/220228-16296409484d2c.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210811/221726-1628691446d92b.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210628/221136-1624889496686d.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210717/003431-16264532710e32.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210725/233656-16272274161bd5.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210818/225551-16292985513847.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210627/225713-1624805833e818.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210628/220957-16248893973b93.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210628/220903-16248893431525.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210628/220813-1624889293b6bd.jpg\n",
      "http://pic.netbian.com/uploads/allimg/210627/225912-1624805952796f.jpg\n"
     ]
    }
   ],
   "source": [
    "dirName = './data/nature_pic'\n",
    "import os \n",
    "if not os.path.exists(dirName):\n",
    "    os.mkdir(dirName)\n",
    "url='http://pic.netbian.com/4kfengjing/'\n",
    "response = requests.get(url=url,headers=headers)\n",
    "response.encoding='gbk'\n",
    "page_text = response.text\n",
    "# print(page_text)\n",
    "tree = etree.HTML(page_text)\n",
    "li_list = tree.xpath('//div[@class=\"slist\"]/ul/li')\n",
    "print(len(li_list))\n",
    "\n",
    "for li in li_list:\n",
    "    title = li.xpath('./a/img/@alt')[0] + '.jpg'\n",
    "    img_src = 'http://pic.netbian.com' + li.xpath('./a/img/@src')[0]\n",
    "    print(img_src)\n",
    "    image_data = requests.get(url=img_src,headers=headers).content\n",
    "    with open(dirName + '/'+title,'wb') as fp:\n",
    "        fp.write(image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bs4直接解析出携带html信息文本串  \n",
    "xpath表达式更具有通用性  \n",
    "xpath可以使用管道符号表示管道符号左右两侧同时生效，如果只有一个生效，那就一个生效"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片懒加载  \n",
    "    需要爬取伪属性，requests本身是没有可视化范围的\n",
    "学过的反爬机制  \n",
    "   robots  \n",
    "    UA伪装  \n",
    "    动态加载  \n",
    "    图片懒加载"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
